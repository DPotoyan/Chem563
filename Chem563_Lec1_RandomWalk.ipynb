{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DPotoyan/Chem563/blob/master/Chem563_Lec1_RandomWalk.ipynb)\n",
    "\n",
    "* ## Lecture 1\n",
    "* ### Random walk into the world of statistical mechanics. \n",
    "* #### $#Random Walk$ $# Random Variable$ $#Binomial distributioons$ $# Normal distribution$ $# Diffusion$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "In this section we will introduce some essential concepts from probability theory while studying a ubqiutously occuring problem of a random walk. Connections with diffusion and ideas of stochastic process are introduced.  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Random walk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to take a close look at the problem of random walk which figures prominently in many physical models such as diffusion, polymers, magnetization.  On the example of random walk we will immeaditely reveal a number of key concepts of probability theory which form the basis of statistical mechanics. In particular we will use random walk for introducing the three most fundamental probability distributions (binomial, gaussian, poisson) and investigating the role of large numbers in justifying wide use of these distributions. Formally, random walk is a mathematical model or object which embodies a commonly occuring situation where some observable of interest takes \"random\" steps according to some probability distribution. Some of the situations described by random walk include molecule of gas going to the left or right part of the box, flippin of a coin or spontaneous magnetizaion by flipping spins or a completely drunk person who walks left or right off of lammpost. The problem of random walk is formulated by specifying the total number of steps $N$ that a random walker makes, the number of steps to the left $N_{+}$ or right $N_{-}$ and their respective probabilities  $p$ and  $q$. Since $N_{+}+N_{-}=N$ and $p+q=1$ we can characterize probability of random walk entirely by the number of steps  n, given the total number of steps N and probability $p$. This is known as conditional probability where n is a variable and N and p are fixed parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(N_{+}|N)= \\frac{N!}{N_{+}! N_{-}!} p^{N_{+}} q^{N_{-}}= \\frac{N!}{N_{+}! (N-N_{+})!} p^{N_{+}} (1-p)^{(N-N_{+})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram bellow shows how probability distribution is generated by consecutive coin flips. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center> <img  src=\"https://upload.wikimedia.org/wikipedia/commons/e/e8/Flips.png\" alt=\"Drawing\" style=\"width: 1500px;\" /> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows plots of binomial distirbution function $P_N(N_{+})$ for several values of p and different number of steps N=n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center> <img  src=\"https://upload.wikimedia.org/wikipedia/commons/7/75/Binomial_distribution_pmf.svg\" alt=\"Drawing\" style=\"width: 500px;\" /> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a problem of diffusion an interesting question to ask is how likely it is to observe the position of molecule after N steps at some distance $x$ which corresponds to making $x=N_{+}-N_{-}$ net steps? Answering this question amounts to a simple change of variables expressing the random walk probability in terms of $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(N_{+}|\\, N,p)=P_N(x)=\\frac{N!}{\\big (\\frac{1}{2}(N+x)\\big)! \\big (\\frac{1}{2}(N-x)\\big)!} p^{\\frac{1}{2}(N+x)} (1-p)^{ \\frac{1}{2}(N-x)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the probability function we are in posessio of maximum informaion about the random walk. This means we can extract means, variances and any other useful functions of distirbution of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mu_x= \\langle x \\rangle =\\sum_x x P_N(x)= N(p-q)$$\n",
    "$$\\sigma^2_x=\\langle (x-\\langle x \\rangle)^2 \\rangle=\\langle x^2 \\rangle-\\langle x \\rangle^2 =\\sum_x x^2 P_N(x)-\\sum_x x P_N(x)= 4Npq$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are easily dervied by making use of binomial theorem (See homework and class notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Each step of a random walk is a random variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined probability of $x$ but let us now understand the nature of $x$ itself. What kind of quanitity is it? Well, it is a quanitity which is different for every sequence of N walks or measruments and is what's known as a realization of a <font color='blue'><em>random variable</font> X. Lets break this down now. At the very first step our molecule makes a \"random\" jump $X_1$ which is can assume two values, either $x_1=+1$ or $x_1=-1$ with probabilities, $p$ and $q$ respectively. We call $X_1$ a random variable becasue it can take different values in different experiment. Likewise $X_2$ would be a random variable for the step 2, $X_3$ for 3rd step etc. Note that we distinguish a random variable X from values x that it takes. In other words x are different realizations of X. Molecular jumps are random variables, finding molecule in right or left box corresponds to jumps having taken values of +1 or -1. Having defined random variables we can now think of the entire walk as yet another random variable $X=\\sum^{N}_{i=1} X_i$ which is a sum of random variables $X_i$ for elementary steps. Naturally, X can take values ranging from -N to N. Our goal is to quanify how likely it is to observe each value $X=x$ for N step random walk, which is accomplished by obtaing probability distirbution function $P_N(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distinguishing aspect of random walk is that every step is completely uncorrelated from all other steps. This random nature of the walk will lead to an important simplifcation and a universal behavior. First, we write down the probability of a single step.  This is accomplished by using kronecker's $\\delta_{q,x}$ symbols which ensure that plugging in values of $x_1$ returns the right value of probability of the moves. That is $P(x_1=+1)=p$ and $P(x_1=-1)=q$ consistent with our definition of random walk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x_1)=p\\delta_{1,x_1}+q\\delta_{-1,x_1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of a sequence of uncorrelated events is given by a product of probabilities of indivudal events. This is an important result in probability theory which which we will formally discuss in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x_1,x_2,...x_N)=P(x_1)P(x_2)...P(x_N)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In first sections we derived mean and variance of X in a straighforward manner by using its probability distribution. For the case of random walk every step is representative of the whole hence for N step random walk one could simply consider the means and variances of any one of the step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mu_{X_1} = \\langle X_1 \\rangle = \\sum_{x_1} p(x_1)x_1=q_r-q_l $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sigma_{X_1}^2 = \\langle X^2_1 \\rangle-\\langle X_1\\rangle^2 = \\sum_{x_1} p(x_1)x^2_1-(q_r-q_l)^2=(q_r+q_l)-(q_r-q_l)^2= 4q_r q_l $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find various notations adopted in books for denoting mean and variance. For example  $ \\mu_a=\\langle a \\rangle =\\bar{a}=E[a]$ and $\\sigma^2_a=V[a]=var_a$. The important thing to keep in mind is over which probability those averages are taken!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance and means for uncorrelated random variables are additive of means and variances of individual steps. This is one of the reasons why variance is useful quantity to compute. See __[wikipeida](https://en.wikipedia.org/wiki/Variance#Sum_of_uncorrelated_variables_(Bienaym%C3%A9_formula)__ article for variance of uncorrelated variables. For the N step random walk the expectation and variance of $X=\\sum_i X_i$ will then be: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mu_X = \\langle X \\rangle =N  \\mu_{X_1}=N(p-q)$$\n",
    "$$ \\sigma_{X}^2 = \\big \\langle X^2 \\big \\rangle -\\langle X \\rangle^2 =N \\sigma^2_{X_1}=4 N pq$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see it explicitely we can obtain the last equality for variance with a bit of care, by keeping track of diagonal and off diagonal terms in the sum. After putting all the terms together we see that variance of the sum of random variables is indeed a sum of variances of individual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Big \\langle\\Big( \\sum_i X_i \\Big)^2 \\Big \\rangle= \\sum_{i} \\langle X^2_i \\rangle+\\sum_i \\sum_j \\langle  X_i X_j\\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sum_{i} \\langle X^2_i \\rangle=N(p+q)$ <br><br>\n",
    "$\\sum_{i} \\sum_{i \\neq i} \\langle X_i X_j \\rangle=\\sum_{i} \\sum_{i \\neq i} \\langle X_i \\rangle \\langle X_j \\rangle =N(N-1) (p-q)^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 The limit of large N: Large deviation function and normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider situation which is common in problems of statistical mechanics. We have accumulated of many steps N (particles, states, etc) and we would like to know how $P_N(x)$ behaves. For large N we can make use of Striling's apporximation: $lnN!=NlnN-N$ or equivalently $N!=N^N e^{-N}$. This allows us to get rid of factorials:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P_N(x)=\\frac{N^N e^{-N}}{\\big (\\frac{N+x}{2}\\big)^{\\frac{N+x}{2}} e^{-\\frac{N+x}{2}} \\big (\\frac{N-x}{2}\\big)^{\\frac{N-x}{2}} e^{-\\frac{N-x}{2}}} p^{\\frac{N+x}{2}} q^{ \\frac{N-x}{2}} =  \\frac{N^N }{\\big (\\frac{N+x}{2}\\big)^{\\frac{N+x}{2}}  \\big (\\frac{N-x}{2}\\big)^{\\frac{N-x}{2}} } p^{\\frac{N+x}{2}} q^{ \\frac{N-x}{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further simplifications happen once we introduce dimensionless quantiaty of fraction of steps $y=x/N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_N(y)=\\frac{1}{\\big (\\frac{1+y}{2}\\big)^{N\\frac{1+y}{2}}  \\big (\\frac{N-x}{2}\\big)^{N\\frac{1-y}{2}} } p^{N\\frac{1+y}{2}} q^{ N\\frac{1-y}{2}}=exp\\Big[-N \\Big (\\frac{1+y}{2}ln \\frac{1+y}{2}+\\frac{1-y}{2}ln \\frac{1-y}{2} +\\frac{1+y}{2}ln p+\\frac{1-y}{2}ln q \\Big )  \\Big ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoiler alert: this is a very signficant result, let us take some time to appreciate it. We have just shown that probability of finding random walker at a particular distance y is governed by an exponentially decaying function with the number of steps N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_N(y)= Ce^{-N I(y)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will see that this is a general result known under the name of large deviation theory (LDT). Large deviation theory, as the name suggests quantified deviations from the mean beavhior and will arm us with powerful set of tools and ideas to  quantify fluctuations and understand deep relationships between seemingly underlated quantities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function in expenention in front of N, $I(y)$ has no dependence on N and this is important to understand too. Shape of I(y) contains valuable information about fluctuations and dynamics of our syste,. In the limit when N becomes overwhelmingly large comparable to avogadro number for instance then clearly the only regions near minima where $I'(y_{min})=0$ will survive which corresponds to the mean of y, $y_{min}=\\langle y \\rangle $. As one may suspect then, becasue of the exponential dependence, fairly often we only need to approximate I(y) in the neighbohood of its minima (or minimas) via a taylor expansion up to quadratic term: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ I(y)=I(y_0)+\\frac{1}{2!} I''(y_0) (y-y_0)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This situation is common that the result distirbution is called normal distribution. In HW you are tasked to fill in the steps and show that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_N(y)=\\frac{1}{ \\sqrt{ 2 \\pi Npq}}e^{-\\frac{(x-N[p-q])^2}{8Npq}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the coefficient in front comes form normalization of gaussian function $\\int p_G(x)=1$  where $P_G(x)= \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{(x-\\mu)/2\\sigma^2}$. Since $\\mu \\sim N$ and $\\sigma_X~\\sim N^{1/2}$, we find that deviation from mean of X, $\\sigma_X/\\mu_X$ decays with increasing number of N as $N^{1/2}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img  src=\"https://upload.wikimedia.org/wikipedia/commons/b/b7/Binomial_Distribution.svg\" alt=\"Drawing\" style=\"width: 300px;\" /> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Emergence of entropy and energy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Connection of random walk with diffusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the reasons the random walk problem is so important in science is becasue it provides a microscopic description of diffusion and diffusive phenomena in general. This connection can be shown readily by deriving the diffusion equation. To do that we consider how probability of N+1 step is evolving in time. First we note that probability of being at state N+1 can evolve from a state N-1 by making either a step to the right or left with probabilities p and q respectively.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{N+1}(x)=pP_{N}(x-1)+qP_{N}(x+1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now specialize to the case of ordinary unbiased diffusion by setting p=q=1/2 and compute how much probability evolves during step $\\Delta N$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{N+1}(x)-P_{N}(x)=\\frac{1}{2} \\big (P_{N}(x-1)+P_{N}(x+1)-2P_{N-1}(x)\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we assume that N and x are large enough that we can regard changes $\\Delta N$ and $\\Delta x$ in a continum, allowing us to translate discrete difference equation into contiuum differential equation. For the continum case it is convenient to introduce the total elapsed time t instead of number of steps by making a following subsitution $N \\rightarrow  \\frac{t}{\\delta t}$ where $\\delta t$ is the time interval between steps. We also introduce continuous distance in terms of length of elementary steps $l$ via\n",
    "$x\\rightarrow  x l$. With these substitution and going to continuum limit we obtain a familiar looking diffusion equation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{t+\\delta t}(x)-P_{t}(x)=\\frac{1}{2} \\big (P_{t}(x-l)+P_{t}(x+l)-2P_{t-\\delta t}(x)\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial P(t,x)}{\\partial t} = D\\frac{\\partial^2 P(t,x)}{\\partial x^2},\\,\\, where\\,\\, D=\\frac{l^2}{2\\delta t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random walk thus decibed the physical phenomena of diffusion of small particles in condensed matter environments with its many conseuqences. Most notably the square root dependence on time of mean square deviation and normall distirbution of steps. An image of brownian motion will suffice now, we will learn more when we simulate brownian motion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img  src=\"https://upload.wikimedia.org/wikipedia/commons/1/18/Random_walk_2000000.png\" alt=\"Drawing\" style=\"width: 300px;\" /> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last diffusion and random walk are commonly used for creating works of art. Check out Antony Gormley's Quantum Cloud sculpture in London which was designed by a computer using a random walk algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img  src=\"https://upload.wikimedia.org/wikipedia/commons/3/3c/Antony_Gormley_Quantum_Cloud_2000.jpg\" alt=\"Drawing\" style=\"width: 300px;\" /> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "\n",
       "<style>\n",
       "div.summary {\n",
       "    background-color: \t#F5F5F5;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 0px solid #F08080;\n",
       "    border-right: 0px solid #F08080;\n",
       "    border-top: 0px solid #F08080;\n",
       "    border-bottom: 0px solid #F08080;\n",
       "    }\n",
       " </style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def set_css_style(css_file_path):\n",
    "    styles = open(css_file_path, \"r\").read()\n",
    "    return HTML(styles)\n",
    "set_css_style('./common/custom.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
